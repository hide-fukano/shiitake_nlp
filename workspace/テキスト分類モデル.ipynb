{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "テキスト分類モデル.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6cn8w74AYhG",
        "colab_type": "text"
      },
      "source": [
        "# テキスト分類モデル構築"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHb8wxPi5mAi",
        "colab_type": "text"
      },
      "source": [
        "## 環境構築"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAmIkCeGJoJR",
        "colab_type": "text"
      },
      "source": [
        "### googleドライブをマウントする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEKniqu-5spi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Drive のマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3j8_Iuq5tys",
        "colab_type": "text"
      },
      "source": [
        "## データ準備\n",
        "\n",
        "|説明変数|目的変数|\n",
        "|:-:|:-:|\n",
        "|診断結果のテキスト|12星座|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix6doxpHLkgy",
        "colab_type": "text"
      },
      "source": [
        "### pandasでデータを読み込む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_0YlIX-5xcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データフレームを操作するためのライブラリ\n",
        "import pandas as pd\n",
        "\n",
        "# CSVファイルを読み込んだあと、dfにデータをデータフレームに格納する\n",
        "df = pd.read_csv('/content/drive/My Drive/pj_horoscopenlp/dataset/shiitake_textdata.csv')\n",
        "\n",
        "# 読み込んだデータの先頭行を表示する\n",
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lCySqT15yKw",
        "colab_type": "text"
      },
      "source": [
        "# データクレンジング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3UuEVT-3eV1",
        "colab_type": "text"
      },
      "source": [
        "### Mecabのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1fndsCrjv2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ColabでMecabをインストールする\n",
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmOOuko_T63G",
        "colab_type": "text"
      },
      "source": [
        "### ライブラリのインポート\n",
        "\n",
        "- どんどん追加していくスタイル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJxJ9QuaThny",
        "colab_type": "text"
      },
      "source": [
        "## 分かち書き"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjsPqzKnWRj0",
        "colab_type": "text"
      },
      "source": [
        "### 「分かち書き」することによって形態素に分解する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ah__zjOsFVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#　形態素解析に必要なライブラリをインポートする\n",
        "  import MeCab\n",
        "\n",
        "  # 文字列をtextに代入\n",
        "  text = '「無理にまとめようとしなくて良いかも」の茶色が出ています。今週の牡牛座はちょっと不思議な時間を過ごしていて、「細かく、やることが多い」というときです。「気づいたら手をつける」という、そういう所用が多くあります。何かをやっている最中に「あ、こっちもやらなきゃ」とか「こっちは変更になった」とか、そういう細かい軌道修正も必要になったりします。こういうときは落ち着いて、あまり「ひとつのゴール」を目指さなくていいです。「目の前にあるものをひとつひとつ終わらせていくこと。別に今の私はまとまりがなくても構わない。手が空いたら気晴らしをしにいく時間も持つ」みたいな感じで大丈夫です。'\n",
        "\n",
        "  # taggerオブジェクトを使う準備\n",
        "  tagger = MeCab.Tagger(\"-Owakati\")\n",
        "\n",
        "  # 分かち書きの結果をresultに代入\n",
        "  result = tagger.parse(text)\n",
        "\n",
        "  # 結果表示\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBJejcBNphrD",
        "colab_type": "text"
      },
      "source": [
        "## 形態素解析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdZDHQeraf_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ライブラリのインポート\n",
        "import MeCab\n",
        "\n",
        "# 文字列をtextに代入\n",
        "text = ('「無理にまとめようとしなくて良いかも」の茶色が出ています。今週の牡牛座はちょっと不思議な時間を過ごしていて、「細かく、やることが多い」というときです。「気づいたら手をつける」という、そういう所用が多くあります。何かをやっている最中に「あ、こっちもやらなきゃ」とか「こっちは変更になった」とか、そういう細かい軌道修正も必要になったりします。こういうときは落ち着いて、あまり「ひとつのゴール」を目指さなくていいです。「目の前にあるものをひとつひとつ終わらせていくこと。別に今の私はまとまりがなくても構わない。手が空いたら気晴らしをしにいく時間も持つ」みたいな感じで大丈夫です。')\n",
        "\n",
        "# taggerオブジェクトを使う準備\n",
        "tagger = MeCab.Tagger()\n",
        "\n",
        "# 分かち書きの結果をresultに代入\n",
        "result = tagger.parse(text)\n",
        "\n",
        "# 結果表示\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "clf2tIOT7P_r"
      },
      "source": [
        "### 新しい辞書をインストールする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "feqaffiS7Pf7",
        "colab": {}
      },
      "source": [
        "# 形態素解析に必要な形態素解析解析エンジンのインポート\n",
        "import MeCab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccwhzuCIqvXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mecab-ipadic-NEologdのダウンロード\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKA7RVUgX4ib",
        "colab_type": "text"
      },
      "source": [
        "### 辞書を使って、文字列に対して品詞を与える"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSdiaHDgtjjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ライブラリのインポート\n",
        "import MeCab\n",
        "\n",
        "# 文字列をtextに代入\n",
        "text = ('あなたは今、色々な展望が開けていくチャンスを目の前に')\n",
        "\n",
        "# taggerオブジェクトを使う準備\n",
        "tagger = MeCab.Tagger('-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd')\n",
        "\n",
        "# 分かち書きの結果をresultに代入\n",
        "result = tagger.parse(text)\n",
        "\n",
        "# 結果表示\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWnfty5hX_4l",
        "colab_type": "text"
      },
      "source": [
        "## ストップワード除去（名詞、動詞、形容詞以外の形態素を取り除く）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvZlItKoSzpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # ストップワードの除去：使用頻度の高い言葉を処理対象外にする\n",
        "  import MeCab\n",
        "  \n",
        "  # mecab-ipadic-NEologd辞書指定してオブジェクト生成\n",
        "  tagger = MeCab.Tagger(\"-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\")\n",
        "  tagger.parse(\"\")\n",
        "  \n",
        "  # 形態素解析の結果をリストで取得、単語ごとにリストの要素に入ってる\n",
        "  node = tagger.parseToNode(\"「無理にまとめようとしなくて良いかも」の茶色が出ています。今週の牡牛座はちょっと不思議な時間を過ごしていて、「細かく、やることが多い」というときです。「気づいたら手をつける」という、そういう所用が多くあります。何かをやっている最中に「あ、こっちもやらなきゃ」とか「こっちは変更になった」とか、そういう細かい軌道修正も必要になったりします。こういうときは落ち着いて、あまり「ひとつのゴール」を目指さなくていいです。「目の前にあるものをひとつひとつ終わらせていくこと。別に今の私はまとまりがなくても構わない。手が空いたら気晴らしをしにいく時間も持つ」みたいな感じで大丈夫です。\")\n",
        "  result = []\n",
        "\n",
        "  #助詞や助動詞は拾わない\n",
        "  while node is not None:\n",
        "      # 品詞情報取得\n",
        "      # Node.featureのフォーマット：品詞,品詞細分類1,品詞細分類2,品詞細分類3,活用形,活用型,原形,読み,発音\n",
        "      hinshi = node.feature.split(\",\")[0]\n",
        "      if hinshi in [\"名詞\"]:\n",
        "          # 表層形の取得、単語の文字が入ってる\n",
        "          result.append(node.surface)\n",
        "      elif hinshi in[\"動詞\",\"形容詞\"]:\n",
        "          # 形態素情報から原形情報取得\n",
        "          result.append(node.feature.split(\",\")[6])\n",
        "      node = node.next\n",
        "\n",
        "  print(result)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So5uSceA50qk",
        "colab_type": "text"
      },
      "source": [
        "# データセット作成 - 単語リストをつくる\n",
        "\n",
        "## データ整形用のメソッドを作る"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObNsA6XMaWB5",
        "colab_type": "text"
      },
      "source": [
        "### 意味が推測できる品詞だけを抽出するメソッド"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX57LDPraVu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# textという引数を使うtokenizeという名前のメソッドを作成\n",
        "def tokenize(text):\n",
        "    # 形態素解析を行って、nodeという変数に格納\n",
        "    node = mecab.parseToNode(text)\n",
        "    # while 文は指定した条件式が真の間、処理を繰り返し実行し続ける\n",
        "    # つまり、テキストデータの中で、名詞と分類される単語がなくなるまで実行し続ける\n",
        "    while node:\n",
        "        # もし、nodeが持っているfeature[0]列にある情報が名詞である場合\n",
        "        if node.feature.split(',')[0] == '名詞':\n",
        "            # 一旦、処理を止めて大文字を小文字に変換する\n",
        "            yield node.surface.lower()\n",
        "        # 一つのnodeに対して処理が終わったので、次のnodeの処理を実行する\n",
        "        node = node.next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpQUvQV8u1H5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# textという引数を使うtokenizeという名前のメソッドを作成\n",
        "def tokenize2(text):\n",
        "    # 形態素解析を行って、nodeという変数に格納\n",
        "    node = mecab.parseToNode(text)\n",
        "    # while 文は指定した条件式が真の間、処理を繰り返し実行し続ける\n",
        "    # つまり、テキストデータの中で、名詞と分類される単語がなくなるまで実行し続ける\n",
        "    while node:\n",
        "      if node.feature.split(\",\")[0] == u\"名詞\" or node.feature.split(',')[0] == '動詞':\n",
        "        node = node.next\n",
        "        # 一旦、処理を止めて大文字を小文字に変換する\n",
        "            #yield node.surface.lower()\n",
        "      # 一つのnodeに対して処理が終わったので、次のnodeの処理を実行する"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_cZNt-hkhfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# textという引数を使うtokenizeという名前のメソッドを作成\n",
        "def tokenize3(text):\n",
        "    # 形態素解析を行って、nodeという変数に格納\n",
        "    node = mecab.parseToNode(text)\n",
        "    # while 文は指定した条件式が真の間、処理を繰り返し実行し続ける\n",
        "    # つまり、テキストデータの中で、名詞と分類される単語がなくなるまで実行し続ける\n",
        "    while node:\n",
        "      if node.feature.split(\",\")[0] == u\"名詞\" or node.feature.split(',')[0] == '形容詞':\n",
        "        node = node.next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMfl-t3ravAk",
        "colab_type": "text"
      },
      "source": [
        "### テキストデータを一つずつ、形態素解析して返すメソッド"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gtbL-qua0dM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_words_main(content):\n",
        "    '''\n",
        "    テキストデータを一つずつ、形態素解析して返す\n",
        "    '''\n",
        "    return [token for token in tokenize3(content)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxt7zXs_adfd",
        "colab_type": "text"
      },
      "source": [
        "### 全てのテキストデータを形態素解析してリストにして返すメソッド\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-tH6FFD54c-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_words(contents):\n",
        "    '''\n",
        "    辞書型になっているデータに対して、形態素解析してリストにして返すメソッド\n",
        "    '''\n",
        "    # retという空の配列を作成\n",
        "    ret = []\n",
        "    # for文=繰り返し処理がしたい　items()は辞書型のデータに対してk, content各要素のキーkeyと値valueの両方に対してforループ処理\n",
        "    for k, content in contents.items():\n",
        "      # append()はリストに対して要素を追加するというメソッド\n",
        "      # retというリストに対して、contentから形態素解析した結果を追加する\n",
        "      ret.append(get_words_main(content))\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drszEiUA7-lo",
        "colab_type": "text"
      },
      "source": [
        "### 形態素解析する必要があるデータをtext_dataという変数に格納する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ur8Pb2uhHsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# textdataだけを配列に代入\n",
        "\n",
        "text_data = df[\"text\"]\n",
        "print(text_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRBu_9cIa83D",
        "colab_type": "text"
      },
      "source": [
        "### 記事を一つずつ形態素解析する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kizZajs4bBA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  import MeCab\n",
        "  mecab = MeCab.Tagger('mecabrc')\n",
        "\n",
        "\n",
        "# 記事を一つずつ形態素解析する\n",
        "# wordという変数にtext_dataにある全て\n",
        "words = get_words(text_data)\n",
        "print(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_BCJiIlgyKO",
        "colab_type": "text"
      },
      "source": [
        "## Gensimを使って特徴語辞書をつくる\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9R17rn7g5Yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import corpora\n",
        "\n",
        "# words には、形態素解析した単語リストが入っている\n",
        "#dictionaryメソッドを使って、単語に対して、IDを振る\n",
        "dictionary = corpora.Dictionary(words)\n",
        "\n",
        "print(dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1R1DBglYyF1",
        "colab_type": "text"
      },
      "source": [
        "### IDと単語の対応表作成（重要度可視化用）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0th6earYwa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = dictionary.token2id\n",
        "\n",
        "word_to_id = pd.DataFrame(d.items(), columns=['word', 'id'])\n",
        "word_to_id = word_to_id[['id', 'word']]\n",
        "word_to_id.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C856Sh_wY43D",
        "colab_type": "text"
      },
      "source": [
        "## 特徴ベクトルへの変換\n",
        "\n",
        "\n",
        " **dictionary.filter_extremes** \n",
        "\n",
        "- no_below : 単語が使われている文章の数が設定値未満の時、その単語を削除\n",
        "- no_above : 単語が使われている文章の割合が設定値以上のとき、その単語を削除\n",
        "- keen_n : 上記二つの設定にかかわらず、指定した数の単語を保持\n",
        "- keep_tokens : 指定した単語を保持"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRguGLSV84Wl",
        "colab_type": "text"
      },
      "source": [
        "### ベクトル化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-DZfh36866C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import corpora\n",
        "\n",
        "dictionary = corpora.Dictionary(words)\n",
        "\n",
        "# 「出現頻度が20未満の単語」と「30%以上の文書で出現する単語」を排除\n",
        "dictionary.filter_extremes(no_below = 20, no_above = 0.3)\n",
        "\n",
        "\n",
        "#dictionary.save_as_text(\"./tmp/dictionary.txt\") で、作成した辞書を保存可能\n",
        "#dictionary = corpora.Dictionary.load_from_text(\"./tmp/dictionary.txt\") で読み込み\n",
        "\n",
        "# bowは今回のスクリプトでは未使用\n",
        "#bow = [dictionary.doc2bow(word) for word in words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pIWG6Ew87HM",
        "colab_type": "text"
      },
      "source": [
        "### 特徴ベクトルへの変換"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B21SyommIXCr",
        "colab_type": "text"
      },
      "source": [
        "- vec2dense：複数のリストに対して一括でベクトル変換できるようにするためのモジュール化する\n",
        "-0 return以降がBoW表現の文章に対する、特徴ベクトルへの変換処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QaUjFaXY5H7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import matutils\n",
        "\n",
        "def vec2dense(vec, num_terms):\n",
        "  # corpus2denseの引数は１文書単位なので、以下のようにモジュール化してリスト内包表記すると良い。\n",
        "  # matutils.corpus2denseは、Gensimコーパスを密行列に変換するメソッド\n",
        "  # num_termsはコーパス内の用語数、今回はコーパスの用語数は同じだからイコール\n",
        "  return list(matutils.corpus2dense([vec], num_terms=num_terms).T[0]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y8BdGxHNbyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# doc2bow()はbag-of-words形式にテキストを変換してくれるメソッド\n",
        "# 特徴語の数（len(dictionary)）だけdoc2bowでベクトル変換した行列を表示する\n",
        "# wordsという抽出した特徴語の数(len(words))の回数だけ（range()）繰り返して、iに代入\n",
        "data_all = [vec2dense(dictionary.doc2bow(words[i]), len(dictionary)) for i in range(len(words))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2pU17n7Y_Sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# この形が特徴ベクトル\n",
        "print(data_all[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYy86yEi9MB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(data_all[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VoH622Q55aT",
        "colab_type": "text"
      },
      "source": [
        "## 機械学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHNKhorKZNuy",
        "colab_type": "text"
      },
      "source": [
        "### 学習用データセット（目的変数の数値化）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GawUAu_SZSwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 正解ラベル\n",
        "\n",
        "label = df[\"label\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fgn5orrOdea",
        "colab_type": "text"
      },
      "source": [
        "### 説明変数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObGbn8knOgSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 説明変数\n",
        "train_data = data_all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CScFDFgOpLA",
        "colab_type": "text"
      },
      "source": [
        "## データ分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s79sY3QdOowl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#パラメーターの過剰適合を防ぐために訓練セットとテストセットを分割しておく\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    train_data, label, test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZbHc9Ps3D12",
        "colab_type": "text"
      },
      "source": [
        "調べるとどうやら、学習データは、1行に一つのデータがあるような構成でなければならないらしい。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDDEYqJl_oU4",
        "colab_type": "text"
      },
      "source": [
        "### 決定木"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLqmyYKc_lBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 決定木に必要なライブラリを読み込み\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 分類器の呼び出し \n",
        "dt = DecisionTreeClassifier(max_depth=3, random_state=0) #今回木の深さは3に設定する\n",
        "# 学習\n",
        "dt.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjOLssjjuKKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 予測\n",
        "dt_pred = dt.predict(X_test)\n",
        "dt_pred[0:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LptHabZOTf2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 検証データで推論した結果をdt_predへ代入\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "# 実際の正解データと照合して正解率を算出\n",
        "accuracy_score(Y_test, dt_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWOA4HGc_rcD",
        "colab_type": "text"
      },
      "source": [
        "### ランダムフォレスト"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN6NF_UX_rQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ランダムフォレストに必要なライブラリを読み込み\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 分類器の呼び出し \n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# 学習\n",
        "rf.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kY6JaJaW96R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 検証データで推論した結果をdt_predへ代入\n",
        "rf_pred = rf.predict(X_test)\n",
        "\n",
        "# 実際の正解データと照合して正解率を算出\n",
        "accuracy_score(Y_test, rf_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iedFmn_jAAOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 予測\n",
        "rf_pred = rf.predict(X_test)\n",
        "rf_pred[0:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qkp0ylLyAPMP",
        "colab_type": "text"
      },
      "source": [
        "### ニューラルネットワーク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr3DIsg-AOyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Neural Networkに必要なライブラリのインストール\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# 分類器の呼び出し \n",
        "NN = MLPClassifier(random_state=0)\n",
        "\n",
        "# 学習\n",
        "NN.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7SeRBtoXVwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 検証データで推論した結果をdt_predへ代入\n",
        "NN_pred = NN.predict(X_test)\n",
        "\n",
        "# 実際の正解データと照合して正解率を算出\n",
        "accuracy_score(Y_test, NN_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqxn7YUtAUtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 予測\n",
        "NN_pred = NN.predict(X_test)\n",
        "NN_pred[0:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRIGrryJuei5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxmVo27m6AUP",
        "colab_type": "text"
      },
      "source": [
        "## 精度検証"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TmaHG8Z6BzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの評価に使用するライブラリを読み込む\n",
        "from sklearn import metrics\n",
        "\n",
        "# 正解率を表示\n",
        "result = pd.DataFrame(\n",
        "    [round(metrics.accuracy_score(Y_test, rf_pred) * 100, 2),\n",
        "     round(metrics.accuracy_score(Y_test, ｄｔ_pred) * 100, 2),\n",
        "     round(metrics.accuracy_score(Y_test, NN_pred) * 100, 2)],\n",
        "    index=['ランダムフォレスト','決定木', 'Neural Network'],\n",
        ").sort_values(by=0, ascending=False)\n",
        "result.columns = ['精度：Accuracy']\n",
        "\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdi8ptCmW4dP",
        "colab_type": "text"
      },
      "source": [
        "# 未知のデータで検証"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1OzlYjvW7rR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# データフレームを操作するためのライブラリ\n",
        "import pandas as pd\n",
        "\n",
        "# CSVファイルを読み込んだあと、dfにデータをデータフレームに格納する\n",
        "test_df = pd.read_csv('/content/drive/My Drive/pj_horoscopenlp/dataset/test_data_sep.csv')\n",
        "\n",
        "# 読み込んだデータの先頭行を表示する\n",
        "test_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGGza7VXGY4r",
        "colab_type": "text"
      },
      "source": [
        "# 参考サイト\n",
        "\n",
        "## データ取得元\n",
        "\n",
        "- [しいたけ占い - 星座・今週の運勢 | 占い | VOGUE GIRL](https://voguegirl.jp/horoscope/shiitake/)\n",
        "\b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ-ZYMOtVQHx",
        "colab_type": "text"
      },
      "source": [
        "# ハマったところ\n",
        "\n",
        "- Runtime Error\n",
        "  - -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
        "  - -d /var/lib/mecab/dic/mecab-ipadic-neologd\n",
        "  \n",
        "  辞書のバージョンが異なる場合はうまく行かない\n",
        "  ローカルだと下の辞書でも上手く言ったが、Colabだと上じゃないとうまく実行されなかった"
      ]
    }
  ]
}